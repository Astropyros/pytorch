I1028 12:24:39.408000 2731790 torch/_dynamo/utils.py:947] ChromiumEventLogger initialized with id 8564d076-424f-406b-9bc6-f4fda09eb2d4
V1028 12:24:39.408000 2731790 torch/_dynamo/convert_frame.py:918] [0/0] torchdynamo start compiling func /home/jessecai/local/pytorch/reproduce_error.py:14, stack (elided 5 frames):
V1028 12:24:39.408000 2731790 torch/_dynamo/convert_frame.py:918] [0/0]   File "/home/jessecai/local/pytorch/reproduce_error.py", line 24, in <module>
V1028 12:24:39.408000 2731790 torch/_dynamo/convert_frame.py:918] [0/0]     print(func())
V1028 12:24:39.408000 2731790 torch/_dynamo/convert_frame.py:918] [0/0] 
I1028 12:24:39.409000 2731790 torch/_dynamo/symbolic_convert.py:2797] [0/0] Step 1: torchdynamo start tracing func /home/jessecai/local/pytorch/reproduce_error.py:14
I1028 12:24:39.409000 2731790 torch/fx/experimental/symbolic_shapes.py:3078] [0/0] create_env
V1028 12:24:39.412000 2731790 torch/_dynamo/symbolic_convert.py:997] [0/0] [__trace_source] TRACE starts_line /home/jessecai/local/pytorch/reproduce_error.py:15 in func (func)
V1028 12:24:39.412000 2731790 torch/_dynamo/symbolic_convert.py:997] [0/0] [__trace_source]         return torch._cslt_sparse_mm(A_sparse, B, alpha=alpha)
V1028 12:24:39.412000 2731790 torch/_dynamo/symbolic_convert.py:1020] [0/0] [__trace_bytecode] TRACE LOAD_GLOBAL torch []
V1028 12:24:39.414000 2731790 torch/_dynamo/symbolic_convert.py:1020] [0/0] [__trace_bytecode] TRACE LOAD_ATTR _cslt_sparse_mm [PythonModuleVariable(<module 'torch' from '/home/jessecai/local/pytorch/torch/__init__.py'>)]
V1028 12:24:39.414000 2731790 torch/_dynamo/symbolic_convert.py:1020] [0/0] [__trace_bytecode] TRACE LOAD_GLOBAL A_sparse [TorchInGraphFunctionVariable(<built-in method _cslt_sparse_mm of type object at 0x7fdc442473c0>)]
V1028 12:24:39.415000 2731790 torch/_dynamo/output_graph.py:2122] [0/0] create_graph_input G_A_sparse_ G['A_sparse']
V1028 12:24:39.415000 2731790 torch/_dynamo/variables/builder.py:2660] [0/0] wrap_to_fake G['A_sparse'] (10240,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], view_base_context=None, tensor_source=GlobalSource(global_name='A_sparse'), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>
V1028 12:24:39.416000 2731790 torch/_dynamo/symbolic_convert.py:1020] [0/0] [__trace_bytecode] TRACE LOAD_GLOBAL B [TorchInGraphFunctionVariable(<built-in method _cslt_sparse_mm of type object at 0x7fdc442473c0>), TensorVariable()]
V1028 12:24:39.416000 2731790 torch/_dynamo/output_graph.py:2122] [0/0] create_graph_input G_B_ G['B']
V1028 12:24:39.417000 2731790 torch/_dynamo/variables/builder.py:2660] [0/0] wrap_to_fake G['B'] (128, 128) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], view_base_context=StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], view_base_context=None, tensor_source=AttrSource(base=GlobalSource(global_name='B'), member='_base'), shape_env_to_source_to_symbol_cache={}), tensor_source=GlobalSource(global_name='B'), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>
V1028 12:24:39.419000 2731790 torch/_dynamo/symbolic_convert.py:1020] [0/0] [__trace_bytecode] TRACE LOAD_GLOBAL alpha [TorchInGraphFunctionVariable(<built-in method _cslt_sparse_mm of type object at 0x7fdc442473c0>), TensorVariable(), TensorVariable()]
V1028 12:24:39.419000 2731790 torch/_dynamo/output_graph.py:2122] [0/0] create_graph_input G_alpha_ G['alpha']
V1028 12:24:39.419000 2731790 torch/_dynamo/variables/builder.py:2660] [0/0] wrap_to_fake G['alpha'] (128,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], view_base_context=None, tensor_source=GlobalSource(global_name='alpha'), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>
V1028 12:24:39.420000 2731790 torch/_dynamo/symbolic_convert.py:1020] [0/0] [__trace_bytecode] TRACE LOAD_CONST ('alpha',) [TorchInGraphFunctionVariable(<built-in method _cslt_sparse_mm of type object at 0x7fdc442473c0>), TensorVariable(), TensorVariable(), TensorVariable()]
V1028 12:24:39.420000 2731790 torch/_dynamo/symbolic_convert.py:1020] [0/0] [__trace_bytecode] TRACE CALL_FUNCTION_KW 3 [TorchInGraphFunctionVariable(<built-in method _cslt_sparse_mm of type object at 0x7fdc442473c0>), TensorVariable(), TensorVariable(), TensorVariable(), TupleVariable(length=1)]
V1028 12:24:39.427000 2731790 torch/_dynamo/symbolic_convert.py:1020] [0/0] [__trace_bytecode] TRACE RETURN_VALUE None [TensorVariable()]
I1028 12:24:39.427000 2731790 torch/_dynamo/symbolic_convert.py:3080] [0/0] Step 1: torchdynamo done tracing func (RETURN_VALUE)
V1028 12:24:39.427000 2731790 torch/_dynamo/symbolic_convert.py:3084] [0/0] RETURN_VALUE triggered compile
V1028 12:24:39.427000 2731790 torch/_dynamo/output_graph.py:1004] [0/0] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/jessecai/local/pytorch/reproduce_error.py, line 15 in func>], graph_break=False)
V1028 12:24:39.430000 2731790 torch/_dynamo/output_graph.py:1372] [0/0] [__graph_code] TRACED GRAPH
V1028 12:24:39.430000 2731790 torch/_dynamo/output_graph.py:1372] [0/0] [__graph_code]  ===== __compiled_fn_1 =====
V1028 12:24:39.430000 2731790 torch/_dynamo/output_graph.py:1372] [0/0] [__graph_code]  /home/jessecai/local/pytorch/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
V1028 12:24:39.430000 2731790 torch/_dynamo/output_graph.py:1372] [0/0] [__graph_code]     def forward(self, G_A_sparse_: "[31mi8[0m[34m[10240][0m[2m[34m[1][0m[2m[32mcuda:0[0m", G_B_: "[31mi8[0m[34m[128, 128][0m[2m[34m[1, 128][0m[2m[32mcuda:0[0m", G_alpha_: "[31mf32[0m[34m[128][0m[2m[34m[1][0m[2m[32mcuda:0[0m"):
V1028 12:24:39.430000 2731790 torch/_dynamo/output_graph.py:1372] [0/0] [__graph_code]         g_a_sparse_ = G_A_sparse_
V1028 12:24:39.430000 2731790 torch/_dynamo/output_graph.py:1372] [0/0] [__graph_code]         g_b_ = G_B_
V1028 12:24:39.430000 2731790 torch/_dynamo/output_graph.py:1372] [0/0] [__graph_code]         g_alpha_ = G_alpha_
V1028 12:24:39.430000 2731790 torch/_dynamo/output_graph.py:1372] [0/0] [__graph_code]         
V1028 12:24:39.430000 2731790 torch/_dynamo/output_graph.py:1372] [0/0] [__graph_code]          [2m# File: /home/jessecai/local/pytorch/reproduce_error.py:15 in func, code: return torch._cslt_sparse_mm(A_sparse, B, alpha=alpha)[0m
V1028 12:24:39.430000 2731790 torch/_dynamo/output_graph.py:1372] [0/0] [__graph_code]         _cslt_sparse_mm: "[31mi8[0m[34m[128, 128][0m[2m[34m[128, 1][0m[2m[32mcuda:0[0m" = torch._cslt_sparse_mm(g_a_sparse_, g_b_, alpha = g_alpha_);  [2mg_a_sparse_ = g_b_ = g_alpha_ = None[0m
V1028 12:24:39.430000 2731790 torch/_dynamo/output_graph.py:1372] [0/0] [__graph_code]         return (_cslt_sparse_mm,)
V1028 12:24:39.430000 2731790 torch/_dynamo/output_graph.py:1372] [0/0] [__graph_code]         
V1028 12:24:39.430000 2731790 torch/_dynamo/output_graph.py:1372] [0/0] [__graph_code] 
I1028 12:24:39.431000 2731790 torch/_dynamo/output_graph.py:1474] [0/0] Step 2: calling compiler function inductor
Traceback (most recent call last):
  File "/home/jessecai/local/pytorch/reproduce_error.py", line 24, in <module>
    print(func())
  File "/home/jessecai/local/pytorch/torch/_dynamo/eval_frame.py", line 554, in _fn
    return fn(*args, **kwargs)
  File "/home/jessecai/local/pytorch/torch/_dynamo/convert_frame.py", line 1401, in __call__
    return self._torchdynamo_orig_callable(
  File "/home/jessecai/local/pytorch/torch/_dynamo/convert_frame.py", line 1184, in __call__
    result = self._inner_convert(
  File "/home/jessecai/local/pytorch/torch/_dynamo/convert_frame.py", line 546, in __call__
    return _compile(
  File "/home/jessecai/local/pytorch/torch/_dynamo/convert_frame.py", line 979, in _compile
    guarded_code = compile_inner(code, one_graph, hooks, transform)
  File "/home/jessecai/local/pytorch/torch/_dynamo/convert_frame.py", line 705, in compile_inner
    return _compile_inner(code, one_graph, hooks, transform)
  File "/home/jessecai/local/pytorch/torch/_utils_internal.py", line 95, in wrapper_function
    return function(*args, **kwargs)
  File "/home/jessecai/local/pytorch/torch/_dynamo/convert_frame.py", line 740, in _compile_inner
    out_code = transform_code_object(code, transform)
  File "/home/jessecai/local/pytorch/torch/_dynamo/bytecode_transformation.py", line 1337, in transform_code_object
    transformations(instructions, code_options)
  File "/home/jessecai/local/pytorch/torch/_dynamo/convert_frame.py", line 231, in _fn
    return fn(*args, **kwargs)
  File "/home/jessecai/local/pytorch/torch/_dynamo/convert_frame.py", line 659, in transform
    tracer.run()
  File "/home/jessecai/local/pytorch/torch/_dynamo/symbolic_convert.py", line 2909, in run
    super().run()
  File "/home/jessecai/local/pytorch/torch/_dynamo/symbolic_convert.py", line 1115, in run
    while self.step():
  File "/home/jessecai/local/pytorch/torch/_dynamo/symbolic_convert.py", line 1027, in step
    self.dispatch_table[inst.opcode](self, inst)
  File "/home/jessecai/local/pytorch/torch/_dynamo/symbolic_convert.py", line 3100, in RETURN_VALUE
    self._return(inst)
  File "/home/jessecai/local/pytorch/torch/_dynamo/symbolic_convert.py", line 3085, in _return
    self.output.compile_subgraph(
  File "/home/jessecai/local/pytorch/torch/_dynamo/output_graph.py", line 1131, in compile_subgraph
    self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
  File "/home/jessecai/local/pytorch/torch/_dynamo/output_graph.py", line 1401, in compile_and_call_fx_graph
    compiled_fn = self.call_user_compiler(gm)
  File "/home/jessecai/local/pytorch/torch/_dynamo/output_graph.py", line 1448, in call_user_compiler
    return self._call_user_compiler(gm)
  File "/home/jessecai/local/pytorch/torch/_dynamo/output_graph.py", line 1497, in _call_user_compiler
    raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
  File "/home/jessecai/local/pytorch/torch/_dynamo/output_graph.py", line 1478, in _call_user_compiler
    compiled_fn = compiler_fn(gm, self.example_inputs())
  File "/home/jessecai/local/pytorch/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
    compiled_gm = compiler_fn(gm, example_inputs)
  File "/home/jessecai/local/pytorch/torch/__init__.py", line 2275, in __call__
    return compile_fx(model_, inputs_, config_patches=self.config)
  File "/home/jessecai/local/pytorch/torch/_inductor/compile_fx.py", line 1398, in compile_fx
    return compile_fx(
  File "/home/jessecai/local/pytorch/torch/_inductor/compile_fx.py", line 1675, in compile_fx
    return aot_autograd(
  File "/home/jessecai/local/pytorch/torch/_dynamo/backends/common.py", line 72, in __call__
    cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
  File "/home/jessecai/local/pytorch/torch/_functorch/aot_autograd.py", line 1105, in aot_module_simplified
    compiled_fn = dispatch_and_compile()
  File "/home/jessecai/local/pytorch/torch/_functorch/aot_autograd.py", line 1081, in dispatch_and_compile
    compiled_fn, _ = create_aot_dispatcher_function(
  File "/home/jessecai/local/pytorch/torch/_functorch/aot_autograd.py", line 528, in create_aot_dispatcher_function
    return _create_aot_dispatcher_function(
  File "/home/jessecai/local/pytorch/torch/_functorch/aot_autograd.py", line 780, in _create_aot_dispatcher_function
    compiled_fn, fw_metadata = compiler_fn(
  File "/home/jessecai/local/pytorch/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 196, in aot_dispatch_base
    compiled_fw = compiler(fw_module, updated_flat_args)
  File "/home/jessecai/local/pytorch/torch/_inductor/compile_fx.py", line 1495, in fw_compiler_base
    return _fw_compiler_base(model, example_inputs, is_inference)
  File "/home/jessecai/local/pytorch/torch/_inductor/compile_fx.py", line 1564, in _fw_compiler_base
    return inner_compile(
  File "/home/jessecai/.conda/envs/pytorch-3.10/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jessecai/local/pytorch/torch/_inductor/compile_fx.py", line 572, in compile_fx_inner
    return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
  File "/home/jessecai/local/pytorch/torch/_dynamo/repro/after_aot.py", line 100, in debug_wrapper
    inner_compiled_fn = compiler_fn(gm, example_inputs)
  File "/home/jessecai/local/pytorch/torch/_inductor/compile_fx.py", line 724, in _compile_fx_inner
    compiled_graph = FxGraphCache.load(
  File "/home/jessecai/local/pytorch/torch/_inductor/codecache.py", line 1479, in load
    compiled_graph = compile_fx_fn(
  File "/home/jessecai/local/pytorch/torch/_inductor/compile_fx.py", line 635, in codegen_and_compile
    compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
  File "/home/jessecai/local/pytorch/torch/_inductor/compile_fx.py", line 942, in fx_codegen_and_compile
    compiled_fn = graph.compile_to_fn()
  File "/home/jessecai/local/pytorch/torch/_inductor/graph.py", line 2028, in compile_to_fn
    return self.compile_to_module().call
  File "/home/jessecai/local/pytorch/torch/_inductor/graph.py", line 1950, in compile_to_module
    return self._compile_to_module()
  File "/home/jessecai/local/pytorch/torch/_inductor/graph.py", line 1956, in _compile_to_module
    self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
  File "/home/jessecai/local/pytorch/torch/_inductor/graph.py", line 1891, in codegen
    self.scheduler = Scheduler(self.operations)
  File "/home/jessecai/local/pytorch/torch/_inductor/scheduler.py", line 1753, in __init__
    self._init(nodes)
  File "/home/jessecai/local/pytorch/torch/_inductor/scheduler.py", line 1835, in _init
    self.finalize_multi_template_buffers()
  File "/home/jessecai/local/pytorch/torch/_inductor/scheduler.py", line 2381, in finalize_multi_template_buffers
    min_node_unfused, _ = multi_node.get_min_choice()
  File "/home/jessecai/local/pytorch/torch/_inductor/ir.py", line 4150, in get_min_choice
    min_choice = min(self.choice_timings, key=self.choice_timings.get)  # type: ignore[arg-type]
  File "/home/jessecai/local/pytorch/torch/_inductor/ir.py", line 4128, in choice_timings
    self._choice_timings = self._choice_timings_fn()
  File "/home/jessecai/local/pytorch/torch/_inductor/select_algorithm.py", line 1390, in get_timings
    timings = do_autotuning(precompile_fn)
  File "/home/jessecai/local/pytorch/torch/_inductor/select_algorithm.py", line 1355, in do_autotuning
    timings = self.lookup(
  File "/home/jessecai/local/pytorch/torch/_inductor/codecache.py", line 370, in lookup
    timings = benchmark(choices)
  File "/home/jessecai/local/pytorch/torch/_inductor/select_algorithm.py", line 1341, in autotune
    return make_benchmark_fn()(choices)
  File "/home/jessecai/local/pytorch/torch/_inductor/select_algorithm.py", line 1553, in benchmark_in_current_process
    raise e
  File "/home/jessecai/local/pytorch/torch/_inductor/select_algorithm.py", line 1519, in benchmark_in_current_process
    timing = benchmark_choice_in_current_process(choice, *inputs)
  File "/home/jessecai/local/pytorch/torch/_inductor/select_algorithm.py", line 1503, in benchmark_choice_in_current_process
    result = choice.benchmark(*example_inputs_extern, out=out_extern)
  File "/home/jessecai/local/pytorch/torch/_inductor/select_algorithm.py", line 968, in benchmark
    out_new = algo(*args)
torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
TypeError: _cslt_sparse_mm(): argument 'alpha' must be Tensor, not StorageBox


You can suppress this exception and fall back to eager by setting:
    import torch._dynamo
    torch._dynamo.config.suppress_errors = True

I1028 12:24:40.160000 2731790 torch/_dynamo/eval_frame.py:385] TorchDynamo attempted to trace the following frames: [
I1028 12:24:40.160000 2731790 torch/_dynamo/eval_frame.py:385]   * func /home/jessecai/local/pytorch/reproduce_error.py:14
I1028 12:24:40.160000 2731790 torch/_dynamo/eval_frame.py:385] ]
I1028 12:24:40.164000 2731790 torch/_dynamo/utils.py:427] TorchDynamo compilation metrics:
I1028 12:24:40.164000 2731790 torch/_dynamo/utils.py:427] Function                                Runtimes (s)
I1028 12:24:40.164000 2731790 torch/_dynamo/utils.py:427] ------------------------------------  --------------
I1028 12:24:40.164000 2731790 torch/_dynamo/utils.py:427] _compile.compile_inner                        0
I1028 12:24:40.164000 2731790 torch/_dynamo/utils.py:427] OutputGraph.call_user_compiler                0
I1028 12:24:40.164000 2731790 torch/_dynamo/utils.py:427] _recursive_pre_grad_passes                    0.0036
I1028 12:24:40.164000 2731790 torch/_dynamo/utils.py:427] create_aot_dispatcher_function                0
I1028 12:24:40.164000 2731790 torch/_dynamo/utils.py:427] compile_fx.<locals>.fw_compiler_base          0
I1028 12:24:40.164000 2731790 torch/_dynamo/utils.py:427] compile_fx_inner                              0
I1028 12:24:40.164000 2731790 torch/_dynamo/utils.py:427] inductor_codecache_torch_key                  0.0833
I1028 12:24:40.164000 2731790 torch/_dynamo/utils.py:427] _recursive_post_grad_passes                   0.002
I1028 12:24:40.164000 2731790 torch/_dynamo/utils.py:427] GraphLowering.run                             0.0165
I1028 12:24:40.164000 2731790 torch/_dynamo/utils.py:427] GraphLowering.compile_to_module               0
I1028 12:24:40.164000 2731790 torch/_dynamo/utils.py:427] Scheduler.__init__                            0
V1028 12:24:40.164000 2731790 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats constrain_symbol_range: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:40.165000 2731790 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats evaluate_expr: CacheInfo(hits=0, misses=0, maxsize=256, currsize=0)
V1028 12:24:40.165000 2731790 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats _simplify_floor_div: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:40.165000 2731790 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats _maybe_guard_rel: CacheInfo(hits=0, misses=0, maxsize=256, currsize=0)
V1028 12:24:40.165000 2731790 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats _find: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:40.165000 2731790 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats has_hint: CacheInfo(hits=0, misses=0, maxsize=256, currsize=0)
V1028 12:24:40.165000 2731790 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats size_hint: CacheInfo(hits=0, misses=0, maxsize=256, currsize=0)
V1028 12:24:40.165000 2731790 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats simplify: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:40.165000 2731790 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats _update_divisible: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:40.165000 2731790 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats replace: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:40.165000 2731790 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats _maybe_evaluate_static: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:40.165000 2731790 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats get_implications: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:40.165000 2731790 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats get_axioms: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:40.165000 2731790 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats _maybe_evaluate_static_worker: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:40.165000 2731790 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats safe_expand: CacheInfo(hits=0, misses=0, maxsize=256, currsize=0)
V1028 12:24:40.166000 2731790 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats uninteresting_files: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
I1028 12:24:41.352000 2732029 torch/_dynamo/eval_frame.py:385] TorchDynamo attempted to trace the following frames: [
I1028 12:24:41.352000 2732029 torch/_dynamo/eval_frame.py:385] 
I1028 12:24:41.352000 2732029 torch/_dynamo/eval_frame.py:385] ]
I1028 12:24:41.357000 2732029 torch/_dynamo/utils.py:427] TorchDynamo compilation metrics:
I1028 12:24:41.357000 2732029 torch/_dynamo/utils.py:427] Function    Runtimes (s)
I1028 12:24:41.357000 2732029 torch/_dynamo/utils.py:427] ----------  --------------
V1028 12:24:41.357000 2732029 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats constrain_symbol_range: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:41.357000 2732029 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats evaluate_expr: CacheInfo(hits=0, misses=0, maxsize=256, currsize=0)
V1028 12:24:41.357000 2732029 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats _simplify_floor_div: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:41.357000 2732029 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats _maybe_guard_rel: CacheInfo(hits=0, misses=0, maxsize=256, currsize=0)
V1028 12:24:41.357000 2732029 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats _find: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:41.357000 2732029 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats has_hint: CacheInfo(hits=0, misses=0, maxsize=256, currsize=0)
V1028 12:24:41.357000 2732029 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats size_hint: CacheInfo(hits=0, misses=0, maxsize=256, currsize=0)
V1028 12:24:41.357000 2732029 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats simplify: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:41.357000 2732029 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats _update_divisible: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:41.358000 2732029 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats replace: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:41.358000 2732029 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats _maybe_evaluate_static: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:41.358000 2732029 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats get_implications: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:41.358000 2732029 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats get_axioms: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:41.358000 2732029 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats _maybe_evaluate_static_worker: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1028 12:24:41.358000 2732029 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats safe_expand: CacheInfo(hits=0, misses=0, maxsize=256, currsize=0)
V1028 12:24:41.358000 2732029 torch/fx/experimental/symbolic_shapes.py:171] lru_cache_stats uninteresting_files: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
